{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import winsorize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenerDataTrain():\n",
    "    train_labels = pd.read_csv('train_labels.csv', index_col='building_id')\n",
    "    train_values = pd.read_csv('train_values.csv', index_col='building_id')\n",
    "    return train_values,train_labels\n",
    "\n",
    "def obtenerDataTest():\n",
    "    return pd.read_csv('test_values.csv', index_col='building_id')\n",
    "\n",
    "def conversionNumericaOneHot(df_datos):\n",
    "    columnas_a_codificar = ['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', \n",
    "                          'other_floor_type', 'position', 'legal_ownership_status', 'plan_configuration']\n",
    "    datos_a_codificar = df_datos[columnas_a_codificar]\n",
    "    datos_codificados, nombres_features_codificados = codificacionOneHot(datos_a_codificar)\n",
    "    \n",
    "    datos_numericos= df_datos[[i for i in list(df_datos.columns) if i not in columnas_a_codificar]]\n",
    "    datos_juntos = np.hstack((datos_codificados,np.array(datos_numericos)))\n",
    "\n",
    "    return datos_juntos\n",
    "\n",
    "def codificacionOneHot(datos_a_codificar):\n",
    "    encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "    datos_codificados = encoder.fit_transform(datos_a_codificar)\n",
    "    nombres_de_los_features = encoder.get_feature_names(datos_a_codificar.columns)\n",
    "    \n",
    "    return datos_codificados, nombres_de_los_features\n",
    "\n",
    "def agregarColumnaBarroMaderaCementoPiedra(data):\n",
    "    data_r=data\n",
    "    data_r['construido_con_barro'] = data['has_superstructure_mud_mortar_brick']+data['has_superstructure_adobe_mud'] \\\n",
    "    +data['has_superstructure_mud_mortar_stone']\n",
    "    barro = [ 1 if l>0 else 0 for l in data_r['construido_con_barro'].values]\n",
    "    data_r['construido_con_barro']=barro\n",
    "\n",
    "    data_r['construido_con_madera'] = data['has_superstructure_timber']+data['has_superstructure_bamboo']\n",
    "    madera = [ 1 if l>0 else 0 for l in data_r['construido_con_madera'].values]\n",
    "    data_r['construido_con_madera']=madera\n",
    "\n",
    "    data_r['construido_con_piedra'] = data['has_superstructure_mud_mortar_stone']+data['has_superstructure_stone_flag']\\\n",
    "                                        +data['has_superstructure_cement_mortar_stone']\n",
    "    piedra = [ 1 if l>0 else 0 for l in data_r['construido_con_piedra'].values]\n",
    "    data_r['construido_con_piedra']=piedra\n",
    "    \n",
    "    \n",
    "    data_r.drop(['has_superstructure_mud_mortar_brick','has_superstructure_adobe_mud','has_superstructure_mud_mortar_stone'\\\n",
    "              ,'has_superstructure_timber','has_superstructure_bamboo','has_superstructure_mud_mortar_stone'\\\n",
    "            ,'has_superstructure_timber','has_superstructure_cement_mortar_stone','has_superstructure_stone_flag'],axis=1,\\\n",
    "                inplace=True)\n",
    "\n",
    "    return data_r\n",
    "\n",
    "def corregirAge(df_values):\n",
    "    df_r = df_values\n",
    "    data = df_r['age']\n",
    "    \n",
    "    winsorized_data = winsorize(data,(0, 0.05))\n",
    "    df_r['age'] = winsorized_data\n",
    "    \n",
    "    return df_r\n",
    "\n",
    "def corregirArea(df_values):\n",
    "    df_r = df_values\n",
    "    data = df_r['area_percentage']\n",
    "    \n",
    "    winsorized_data = winsorize(data,(0, 0.055))\n",
    "    df_r['area_percentage'] = winsorized_data\n",
    "    \n",
    "    return df_r\n",
    "\n",
    "def corregiraAltura(df_values):\n",
    "    df_r = df_values\n",
    "    data = df_r['height_percentage']\n",
    "    \n",
    "    winsorized_data = winsorize(data,(0, 0.04))\n",
    "    df_r['height_percentage'] = winsorized_data\n",
    "    \n",
    "    return df_r\n",
    "\n",
    "def limpiarColumnsSec(values):\n",
    "    df_r=values\n",
    "    df_r['uso_secundario']=df_r['has_secondary_use']+df_r['has_secondary_use_agriculture']+\\\n",
    "                df_r['has_secondary_use_hotel']+df_r['has_secondary_use_gov_office']\\\n",
    "              +df_r['has_secondary_use_rental']+df_r['has_secondary_use_institution']+df_r['has_secondary_use_school']\\\n",
    "              +df_r['has_secondary_use_industry']+df_r['has_secondary_use_industry']+df_r['has_secondary_use_health_post']\\\n",
    "              +df_r['has_secondary_use_use_police']+df_r['has_secondary_use_other']\n",
    "    \n",
    "    secundario = [ 1 if l>0 else 0 for l in df_r['uso_secundario'].values]\n",
    "    df_r['uso_secundario']=secundario\n",
    "    \n",
    "    df_r.drop(['has_secondary_use','has_secondary_use_agriculture','has_secondary_use_hotel','has_secondary_use_gov_office'\\\n",
    "              ,'has_secondary_use_rental','has_secondary_use_institution','has_secondary_use_school'\\\n",
    "              ,'has_secondary_use_industry','has_secondary_use_industry','has_secondary_use_health_post'\\\n",
    "              ,'has_secondary_use_use_police','has_secondary_use_other','count_families'], axis=1, inplace=True)\n",
    "    return df_r\n",
    "\n",
    "    \n",
    "def var(x,y):\n",
    "    return pow(x-y,2)\n",
    "\n",
    "def agregarVarianzaId1(df_values):\n",
    "    df_r=df_values\n",
    "    id_1 = df_values['geo_level_1_id']\n",
    "    mean_id = df_values['geo_level_1_id'].mean()\n",
    "    varianza = [ var(x,mean_id) for x in df_values['geo_level_1_id'].values]\n",
    "    df_r['var_geo_level_1_id']=varianza\n",
    "    return df_r\n",
    "\n",
    "\n",
    "def agregarFeatures(data):\n",
    "    col_superstructure = ['has_superstructure_adobe_mud',\n",
    "          'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "          'has_superstructure_cement_mortar_stone',\n",
    "          'has_superstructure_mud_mortar_brick',\n",
    "          'has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "          'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered',\n",
    "          'has_superstructure_rc_engineered', 'has_superstructure_other']\n",
    "    col_mortar = ['has_superstructure_mud_mortar_stone', 'has_superstructure_cement_mortar_stone',\n",
    "                  'has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick']\n",
    "    col_mud = ['has_superstructure_adobe_mud', 'has_superstructure_mud_mortar_stone',\n",
    "                'has_superstructure_mud_mortar_brick']\n",
    "    col_stone = ['has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag',\n",
    "                  'has_superstructure_cement_mortar_stone']\n",
    "    col_cement = ['has_superstructure_cement_mortar_stone', 'has_superstructure_cement_mortar_brick']\n",
    "    col_brick = ['has_superstructure_mud_mortar_brick', 'has_superstructure_cement_mortar_brick']\n",
    "    col_wood = ['has_superstructure_timber','has_superstructure_bamboo']\n",
    "\n",
    "    col_geolevel1 = ['geo_level_1_id', 'geo_level_2_id', 'geo_level_3_id']\n",
    "    data['geolevel_sum1'] = data[col_geolevel1].sum(axis=1)\n",
    "\n",
    "    col_geolevel2 = ['geo_level_2_id', 'geo_level_3_id']\n",
    "    data['geolevel_sum2'] = data[col_geolevel2].sum(axis=1)\n",
    "\n",
    "    data['wood_count'] = data[col_wood].sum(axis=1)\n",
    "    #habria que ver si tiene sentido sumar los superstructure\n",
    "    data['superstructure_count'] = data[col_superstructure].sum(axis=1)\n",
    "    #habria que ver si tiene sentido sumar los mortar\n",
    "    data['mortar_count'] = data[col_mortar].sum(axis=1)\n",
    "    data['mud_count'] = data[col_mud].sum(axis=1)\n",
    "    data['stone_count'] = data[col_stone].sum(axis=1)\n",
    "    data['cement_count'] = data[col_cement].sum(axis=1)\n",
    "    data['brick_count'] = data[col_brick].sum(axis=1)\n",
    "    #habria que chequear el nivel de importancia\n",
    "    data['family_per_floor'] = data['count_families']/data['count_floors_pre_eq']\n",
    "    data['volumen_percentage'] = data['area_percentage']*data['height_percentage']\n",
    "\n",
    "    data.drop(col_wood+col_mortar+col_mud+col_stone+col_cement+col_brick+col_wood,axis=1,inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def dummyEncoding(data):\n",
    "    categorical_features = ['land_surface_condition', 'foundation_type', 'roof_type', 'ground_floor_type', \n",
    "                          'other_floor_type']\n",
    "    data = pd.get_dummies(data,columns=categorical_features,drop_first=True)\n",
    "    \n",
    "    data.drop(['position', 'legal_ownership_status', 'plan_configuration'], axis=1, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def preprocess_numeric_data(data):\n",
    "    numerical_features = ['age', 'area_percentage', 'height_percentage', 'volumen_percentage']\n",
    "    scaler = StandardScaler()\n",
    "    df = pd.DataFrame(scaler.fit_transform(data[numerical_features]), columns=numerical_features)\n",
    "    data[numerical_features]=df[numerical_features].copy()\n",
    "    return data\n",
    "\n",
    "def agregarClusters(data):\n",
    "    data_r=data\n",
    "    data_r['2_clusters'] = KMeans(n_clusters=2, random_state=0).fit_predict(data.values)\n",
    "    data_r['4_clusters'] = KMeans(n_clusters=4, random_state=0).fit_predict(data.values)\n",
    "    data_r['10_clusters'] = KMeans(n_clusters=10, random_state=0).fit_predict(data.values)\n",
    "    return data_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandirDataSet(df_values):\n",
    "    values_process = agregarFeatures(df_values)\n",
    "    values_process = agregarVarianzaId1(values_process)\n",
    "    values_process = limpiarColumnsSec(values_process)\n",
    "    values_process = agregarClusters(values_process)\n",
    "\n",
    "    return values_process\n",
    "\n",
    "def prepararDataSet(df_values):\n",
    "    values_process = corregirAge(df_values)\n",
    "    values_process = corregirArea(values_process)\n",
    "    values_process = corregiraAltura(values_process)\n",
    "    return values_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
